{
 "cells": [
  {
   "cell_type": "code",
   "id": "3a2906aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T16:45:55.966484Z",
     "start_time": "2025-05-15T16:45:27.692724Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# === Paths ===\n",
    "base_input_dir = \"FD_csv_EEC\"\n",
    "bronze_output_dir = os.path.join(\"emploi\", \"parquet\", \"bronze\")\n",
    "os.makedirs(bronze_output_dir, exist_ok=True)\n",
    "\n",
    "# === Load and prepare metadata once ===\n",
    "metadata_file = os.path.join(base_input_dir, \"Varmod_EEC.csv\")\n",
    "metadata_df = pd.read_csv(metadata_file, sep=';', encoding='utf-8')\n",
    "unique_vars = metadata_df[['COD_VAR', 'TYPE_VAR']].drop_duplicates()\n",
    "\n",
    "type_map = {\n",
    "    'NUM': 'float',\n",
    "    'CHAR': 'string',\n",
    "    'DATE': 'datetime'\n",
    "}\n",
    "\n",
    "dtype_mapping = {\n",
    "    row['COD_VAR']: type_map.get(row['TYPE_VAR'], 'string')\n",
    "    for _, row in unique_vars.iterrows()\n",
    "}\n",
    "\n",
    "# === Process each year's CSV ===\n",
    "for file_path in glob.glob(os.path.join(base_input_dir, \"FD_EEC_*.csv\")):\n",
    "    year_str = os.path.basename(file_path).split(\"_\")[-1].split(\".\")[0]\n",
    "    print(f\"Processing file for year {year_str}\")\n",
    "\n",
    "    df = pd.read_csv(file_path, sep=';', encoding='utf-8')\n",
    "\n",
    "    if 'ANNEE' not in df.columns:\n",
    "        df['ANNEE'] = int(year_str)\n",
    "\n",
    "    for col, dtype in dtype_mapping.items():\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        try:\n",
    "            if dtype == 'datetime':\n",
    "                df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "            else:\n",
    "                df[col] = df[col].astype(dtype)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {col} to {dtype}: {e}\")\n",
    "\n",
    "    # Save as Parquet\n",
    "    output_parquet = os.path.join(bronze_output_dir, f\"df_bronze_emploi_EEC{year_str}.parquet\")\n",
    "    df.to_parquet(output_parquet, index=False)\n",
    "    print(f\"Saved: {output_parquet}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file for year 2018\n",
      "Saved: emploi\\parquet\\bronze\\df_bronze_emploi_EEC2018.parquet\n",
      "Processing file for year 2019\n",
      "Saved: emploi\\parquet\\bronze\\df_bronze_emploi_EEC2019.parquet\n",
      "Processing file for year 2020\n",
      "Saved: emploi\\parquet\\bronze\\df_bronze_emploi_EEC2020.parquet\n",
      "Processing file for year 2021\n",
      "Saved: emploi\\parquet\\bronze\\df_bronze_emploi_EEC2021.parquet\n",
      "Processing file for year 2022\n",
      "Saved: emploi\\parquet\\bronze\\df_bronze_emploi_EEC2022.parquet\n",
      "Processing file for year 2023\n",
      "Saved: emploi\\parquet\\bronze\\df_bronze_emploi_EEC2023.parquet\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "e66cfca9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T16:46:24.129086Z",
     "start_time": "2025-05-15T16:45:55.977919Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# === Paths ===\n",
    "bronze_dir = os.path.join(\"emploi\", \"parquet\", \"bronze\")\n",
    "silver_dir = os.path.join(\"emploi\", \"parquet\", \"silver\")\n",
    "os.makedirs(silver_dir, exist_ok=True)\n",
    "\n",
    "# === Process all Bronze Parquet files ===\n",
    "for bronze_path in glob.glob(os.path.join(bronze_dir, \"df_bronze_emploi_EEC*.parquet\")):\n",
    "    year_str = os.path.basename(bronze_path).split(\"EEC\")[-1].split(\".\")[0]\n",
    "    print(f\"\\nProcessing year: {year_str}\")\n",
    "\n",
    "    df = pd.read_parquet(bronze_path)\n",
    "\n",
    "    # === Cleaning ===\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Drop rows missing the 'ANNEE' column if present\n",
    "    if 'ANNEE' in df.columns:\n",
    "        df.dropna(subset=['ANNEE'], inplace=True)\n",
    "    else:\n",
    "        df['ANNEE'] = int(year_str)\n",
    "\n",
    "    # Save cleaned file to Silver\n",
    "    silver_path = os.path.join(silver_dir, f\"df_silver_emploi_EEC{year_str}.parquet\")\n",
    "    df.to_parquet(silver_path, index=False)\n",
    "\n",
    "    print(f\"Saved cleaned Silver file: {silver_path} ({df.shape[0]} rows)\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing year: 2018\n",
      "Saved cleaned Silver file: emploi\\parquet\\silver\\df_silver_emploi_EEC2018.parquet (423283 rows)\n",
      "\n",
      "Processing year: 2019\n",
      "Saved cleaned Silver file: emploi\\parquet\\silver\\df_silver_emploi_EEC2019.parquet (415031 rows)\n",
      "\n",
      "Processing year: 2020\n",
      "Saved cleaned Silver file: emploi\\parquet\\silver\\df_silver_emploi_EEC2020.parquet (318427 rows)\n",
      "\n",
      "Processing year: 2021\n",
      "Saved cleaned Silver file: emploi\\parquet\\silver\\df_silver_emploi_EEC2021.parquet (343304 rows)\n",
      "\n",
      "Processing year: 2022\n",
      "Saved cleaned Silver file: emploi\\parquet\\silver\\df_silver_emploi_EEC2022.parquet (348964 rows)\n",
      "\n",
      "Processing year: 2023\n",
      "Saved cleaned Silver file: emploi\\parquet\\silver\\df_silver_emploi_EEC2023.parquet (348624 rows)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T16:46:31.218264Z",
     "start_time": "2025-05-15T16:46:24.390769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# === Paths ===\n",
    "silver_dir = os.path.join(\"emploi\", \"parquet\", \"silver\")\n",
    "gold_dir = os.path.join(\"emploi\", \"parquet\", \"gold\")\n",
    "os.makedirs(gold_dir, exist_ok=True)\n",
    "summary_output_path = os.path.join(gold_dir, \"df_gold_emploi_summary.parquet\")\n",
    "\n",
    "# === Collect data from all Silver files ===\n",
    "required_columns = ['AGE6', 'SEXE', 'ACTEU', 'EXTRIAN', 'STATUT', 'STATUTDET', 'TPPRED', 'ANNEE']\n",
    "df_all = []\n",
    "\n",
    "for silver_path in glob.glob(os.path.join(silver_dir, \"df_silver_emploi_EEC*.parquet\")):\n",
    "    print(f\"Reading {os.path.basename(silver_path)}\")\n",
    "    df = pd.read_parquet(silver_path)\n",
    "\n",
    "    # Filter required columns\n",
    "    available_cols = [col for col in required_columns if col in df.columns]\n",
    "    df = df[available_cols]\n",
    "\n",
    "    # Ensure ANNEE and EXTRIAN are numeric\n",
    "    df = df[df['ANNEE'].notna()]\n",
    "    df['ANNEE'] = df['ANNEE'].astype(int)\n",
    "    df['EXTRIAN'] = pd.to_numeric(df['EXTRIAN'], errors='coerce').fillna(0)\n",
    "\n",
    "    df_all.append(df)\n",
    "\n",
    "# Combine all years\n",
    "df_all_years = pd.concat(df_all, ignore_index=True)\n",
    "\n",
    "# === Compute indicators grouped by ANNEE ===\n",
    "# Ensure EXTRIAN and ACTEU are numeric\n",
    "df_all_years['EXTRIAN'] = pd.to_numeric(df_all_years['EXTRIAN'], errors='coerce')\n",
    "df_all_years['ACTEU'] = pd.to_numeric(df_all_years['ACTEU'], errors='coerce')\n",
    "\n",
    "# Filter for relevant rows\n",
    "df_chomeurs = df_all_years[df_all_years['ACTEU'] == 2]\n",
    "df_actifs = df_all_years[df_all_years['ACTEU'].isin([1, 2])]\n",
    "\n",
    "# Compute sums of EXTRIAN per year\n",
    "sum_chomeurs = df_chomeurs.groupby('ANNEE')['EXTRIAN'].sum()\n",
    "sum_actifs = df_actifs.groupby('ANNEE')['EXTRIAN'].sum()\n",
    "\n",
    "# Compute taux_chomage safely\n",
    "summary = pd.DataFrame({\n",
    "    'taux_chomage': 100 * sum_chomeurs / sum_actifs\n",
    "}).reset_index()\n",
    "\n",
    "summary['taux_chomage'] = summary['taux_chomage'].round(2)\n",
    "\n",
    "# === Save summary ===\n",
    "summary.to_parquet(summary_output_path, index=False)\n",
    "\n",
    "print(f\"Weighted employment summary saved to: {summary_output_path}\")\n",
    "print(summary)\n"
   ],
   "id": "433c2494f9c861eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading df_silver_emploi_EEC2018.parquet\n",
      "Reading df_silver_emploi_EEC2019.parquet\n",
      "Reading df_silver_emploi_EEC2020.parquet\n",
      "Reading df_silver_emploi_EEC2021.parquet\n",
      "Reading df_silver_emploi_EEC2022.parquet\n",
      "Reading df_silver_emploi_EEC2023.parquet\n",
      "Weighted employment summary saved to: emploi\\parquet\\gold\\df_gold_emploi_summary.parquet\n",
      "   ANNEE  taux_chomage\n",
      "0   2018          9.06\n",
      "1   2019          8.44\n",
      "2   2020          8.01\n",
      "3   2021          7.86\n",
      "4   2022          7.31\n",
      "5   2023          7.33\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
