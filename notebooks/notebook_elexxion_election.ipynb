{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T16:23:32.894498Z",
     "start_time": "2025-05-17T16:23:32.609544Z"
    }
   },
   "source": [
    "import spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, current_timestamp, lpad, concat, expr, row_number\n",
    "from pyspark.sql.types import StringType\n",
    "import os\n",
    "\n",
    "# Arr√™ter la session Spark existante si n√©cessaire\n",
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Initialisation de Spark\n",
    "spark = SparkSession.builder.appName(\"Election Data Pipeline\").getOrCreate()\n",
    "\n",
    "# === Configurations ===\n",
    "BRONZE_PATH = \"/content/bronze\"\n",
    "SILVER_PATH = \"/content/silver\"\n",
    "GOLD_PATH = \"/content/gold\"\n",
    "CANDIDAT_PATH = f\"{GOLD_PATH}/candidats\"\n",
    "\n",
    "# Cr√©er les dossiers n√©cessaires\n",
    "os.makedirs(BRONZE_PATH, exist_ok=True)\n",
    "os.makedirs(SILVER_PATH, exist_ok=True)\n",
    "os.makedirs(GOLD_PATH, exist_ok=True)\n",
    "os.makedirs(CANDIDAT_PATH, exist_ok=True)\n",
    "\n",
    "# === Fichiers Sources === (Assurez-vous d'avoir upload√© vos fichiers dans /content)\n",
    "RAW_FILES = [\n",
    "    (\"/content/resultats-par-niveau-subcom-t1-france-entiere.csv\", \"2022\", \"T1\"),\n",
    "    (\"/content/resultats-par-niveau-subcom-t2-france-entiere-_4_.csv\", \"2022\", \"T2\"),\n",
    "    (\"/content/Presidentiel_2017_1erTour.csv\", \"2017\", \"T1\"),\n",
    "    (\"/content/presidentielle_2017_Tour2.csv\", \"2017\", \"T2\"),\n",
    "    (\"/content/presidentiel_2012_T1.csv\", \"2012\", \"T1\"),\n",
    "    (\"/content/presidentiel_2012_t2.csv\", \"2012\", \"T2\")\n",
    "]\n",
    "\n",
    "# Fonction nettoyage\n",
    "def clean_columns(df):\n",
    "    for col_name in df.columns:\n",
    "        new_name = col_name.lower().strip().replace(\" \", \"_\").replace(\"%\", \"pct\").replace(\"/\", \"_\").replace(\".\", \"\")\n",
    "        df = df.withColumnRenamed(col_name, new_name)\n",
    "    if \"exprim√©s\" in df.columns:\n",
    "        df = df.withColumnRenamed(\"exprim√©s\", \"exprimes\")\n",
    "    return df\n"
   ],
   "outputs": [
    {
     "ename": "PySparkRuntimeError",
     "evalue": "[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mPySparkRuntimeError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[40]\u001B[39m\u001B[32m, line 14\u001B[39m\n\u001B[32m     11\u001B[39m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m     13\u001B[39m \u001B[38;5;66;03m# Initialisation de Spark\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m spark = \u001B[43mSparkSession\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbuilder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mappName\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mElection Data Pipeline\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgetOrCreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[38;5;66;03m# === Configurations ===\u001B[39;00m\n\u001B[32m     17\u001B[39m BRONZE_PATH = \u001B[33m\"\u001B[39m\u001B[33m/content/bronze\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\GitHub\\Elexxion\\.venv\\Lib\\site-packages\\pyspark\\sql\\session.py:497\u001B[39m, in \u001B[36mSparkSession.Builder.getOrCreate\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    495\u001B[39m     sparkConf.set(key, value)\n\u001B[32m    496\u001B[39m \u001B[38;5;66;03m# This SparkContext may be an existing one.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m497\u001B[39m sc = \u001B[43mSparkContext\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgetOrCreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msparkConf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    498\u001B[39m \u001B[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001B[39;00m\n\u001B[32m    499\u001B[39m \u001B[38;5;66;03m# by all sessions.\u001B[39;00m\n\u001B[32m    500\u001B[39m session = SparkSession(sc, options=\u001B[38;5;28mself\u001B[39m._options)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\GitHub\\Elexxion\\.venv\\Lib\\site-packages\\pyspark\\context.py:515\u001B[39m, in \u001B[36mSparkContext.getOrCreate\u001B[39m\u001B[34m(cls, conf)\u001B[39m\n\u001B[32m    513\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m SparkContext._lock:\n\u001B[32m    514\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m SparkContext._active_spark_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m515\u001B[39m         \u001B[43mSparkContext\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconf\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconf\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mSparkConf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    516\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m SparkContext._active_spark_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    517\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m SparkContext._active_spark_context\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\GitHub\\Elexxion\\.venv\\Lib\\site-packages\\pyspark\\context.py:201\u001B[39m, in \u001B[36mSparkContext.__init__\u001B[39m\u001B[34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001B[39m\n\u001B[32m    195\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m gateway \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m gateway.gateway_parameters.auth_token \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    196\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    197\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mYou are trying to pass an insecure Py4j gateway to Spark. This\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    198\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m is not allowed as it is a security risk.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    199\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m201\u001B[39m \u001B[43mSparkContext\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_ensure_initialized\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgateway\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgateway\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconf\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    202\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    203\u001B[39m     \u001B[38;5;28mself\u001B[39m._do_init(\n\u001B[32m    204\u001B[39m         master,\n\u001B[32m    205\u001B[39m         appName,\n\u001B[32m   (...)\u001B[39m\u001B[32m    215\u001B[39m         memory_profiler_cls,\n\u001B[32m    216\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\GitHub\\Elexxion\\.venv\\Lib\\site-packages\\pyspark\\context.py:436\u001B[39m, in \u001B[36mSparkContext._ensure_initialized\u001B[39m\u001B[34m(cls, instance, gateway, conf)\u001B[39m\n\u001B[32m    434\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m SparkContext._lock:\n\u001B[32m    435\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m SparkContext._gateway:\n\u001B[32m--> \u001B[39m\u001B[32m436\u001B[39m         SparkContext._gateway = gateway \u001B[38;5;129;01mor\u001B[39;00m \u001B[43mlaunch_gateway\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    437\u001B[39m         SparkContext._jvm = SparkContext._gateway.jvm\n\u001B[32m    439\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m instance:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\GitHub\\Elexxion\\.venv\\Lib\\site-packages\\pyspark\\java_gateway.py:107\u001B[39m, in \u001B[36mlaunch_gateway\u001B[39m\u001B[34m(conf, popen_kwargs)\u001B[39m\n\u001B[32m    104\u001B[39m     time.sleep(\u001B[32m0.1\u001B[39m)\n\u001B[32m    106\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os.path.isfile(conn_info_file):\n\u001B[32m--> \u001B[39m\u001B[32m107\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkRuntimeError(\n\u001B[32m    108\u001B[39m         error_class=\u001B[33m\"\u001B[39m\u001B[33mJAVA_GATEWAY_EXITED\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    109\u001B[39m         message_parameters={},\n\u001B[32m    110\u001B[39m     )\n\u001B[32m    112\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(conn_info_file, \u001B[33m\"\u001B[39m\u001B[33mrb\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m info:\n\u001B[32m    113\u001B[39m     gateway_port = read_int(info)\n",
      "\u001B[31mPySparkRuntimeError\u001B[39m: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number."
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_bronze = []\n",
    "for file_path, year, tour in RAW_FILES:\n",
    "    df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(file_path)\n",
    "    df = df.withColumn(\"ingestion_date\", current_timestamp()) \\\n",
    "           .withColumn(\"annee\", lit(year)) \\\n",
    "           .withColumn(\"tour\", lit(tour))\n",
    "    df.coalesce(1).write.mode(\"overwrite\").parquet(f\"{BRONZE_PATH}/election_{year}_{tour}.parquet\")\n",
    "    dfs_bronze.append(df)\n",
    "\n",
    "print(\"‚úÖ √âtape 1 : BRONZE termin√©e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_silver = []\n",
    "for df in dfs_bronze:\n",
    "    df = clean_columns(df)\n",
    "    df = df.dropna(how=\"all\").dropDuplicates()\n",
    "\n",
    "    if \"votants\" in df.columns and \"inscrits\" in df.columns:\n",
    "        df = df.withColumn(\"taux_participation\", (col(\"votants\") / col(\"inscrits\")))\n",
    "    if \"abstentions\" in df.columns and \"inscrits\" in df.columns:\n",
    "        df = df.withColumn(\"taux_abstention\", (col(\"abstentions\") / col(\"inscrits\")))\n",
    "    if \"blancs\" in df.columns and \"votants\" in df.columns:\n",
    "        df = df.withColumn(\"taux_blancs\", (col(\"blancs\") / col(\"votants\")))\n",
    "\n",
    "    if \"code_du_d√©partement\" in df.columns and \"code_de_la_commune\" in df.columns:\n",
    "        df = df.withColumn(\n",
    "            \"code_insee\",\n",
    "            concat(\n",
    "                lpad(col(\"code_du_d√©partement\").cast(StringType()), 2, \"0\"),\n",
    "                lpad(col(\"code_de_la_commune\").cast(StringType()), 3, \"0\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "    year, tour = df.select(\"annee\").first()[0], df.select(\"tour\").first()[0]\n",
    "    df.coalesce(1).write.mode(\"overwrite\").parquet(f\"{SILVER_PATH}/election_{year}_{tour}.parquet\")\n",
    "    dfs_silver.append(df)\n",
    "\n",
    "print(\"‚úÖ √âtape 2 : SILVER termin√©e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_columns = [\"code_du_d√©partement\", \"libell√©_du_d√©partement\", \"inscrits\", \"abstentions\", \"votants\", \"exprimes\", \"annee\", \"tour\", \"taux_participation\", \"taux_abstention\", \"taux_blancs\", \"code_insee\"]\n",
    "gold_df = None\n",
    "for df in dfs_silver:\n",
    "    available_cols = [col for col in gold_columns if col in df.columns]\n",
    "    current = df.select(*available_cols)\n",
    "    gold_df = current if gold_df is None else gold_df.unionByName(current, allowMissingColumns=True)\n",
    "\n",
    "gold_df.coalesce(1).write.mode(\"overwrite\").parquet(f\"{GOLD_PATH}/elections_unifiees.parquet\")\n",
    "print(\"‚úÖ √âtape 3 : GOLD termin√©e\")\n",
    "gold_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidat_dfs = []\n",
    "for df in dfs_silver:\n",
    "    if all(c in df.columns for c in [\"nom\", \"pr√©nom\", \"voix\", \"exprimes\"]):\n",
    "        candidat_df = df.select(\n",
    "            \"code_insee\", \"annee\", \"tour\", \"nom\", \"pr√©nom\", \"voix\", \"exprimes\",\n",
    "            \"taux_participation\", \"taux_abstention\", \"taux_blancs\"\n",
    "        ).withColumn(\"nom_complet\", expr(\"concat(`pr√©nom`, ' ', nom)\")) \\\n",
    "         .withColumn(\"pct_voix_exprimes\", col(\"voix\") / col(\"exprimes\"))\n",
    "\n",
    "        candidat_df = candidat_df.select(\n",
    "            \"code_insee\", \"annee\", \"tour\", \"nom_complet\", \"voix\", \"pct_voix_exprimes\",\n",
    "            \"taux_participation\", \"taux_abstention\", \"taux_blancs\"\n",
    "        )\n",
    "\n",
    "        candidat_dfs.append(candidat_df)\n",
    "\n",
    "if candidat_dfs:\n",
    "    candidats_all = candidat_dfs[0]\n",
    "    for d in candidat_dfs[1:]:\n",
    "        candidats_all = candidats_all.unionByName(d, allowMissingColumns=True)\n",
    "\n",
    "    candidats_all.coalesce(1).write.mode(\"overwrite\").parquet(f\"{CANDIDAT_PATH}/resultats_par_candidat.parquet\")\n",
    "    print(\"‚úÖ √âtape 4 : CANDIDATS termin√©e\")\n",
    "    candidats_all.show(10)\n",
    "\n",
    "print(\"üéâ Pipeline complet termin√© avec succ√®s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
