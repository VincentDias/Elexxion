# Databricks notebook Python (PySpark)
# Pipeline : Bronze ‚Üí Silver ‚Üí Gold + Extraction par candidat pour les √©lections pr√©sidentielles 2012, 2017, 2022 (2 tours)

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, lit, current_timestamp, when, lpad, concat, expr
from pyspark.sql.types import StringType
import os

spark = SparkSession.builder.appName("ElectionETL").getOrCreate()

# === Configurations ===
BRONZE_PATH = "/mnt/data/bronze"
SILVER_PATH = "/mnt/data/silver"
GOLD_PATH = "/mnt/data/gold"
CANDIDAT_PATH = "/mnt/data/candidat"
RAW_FILES = [
    ("/FileStore/tables/MSPR_presidentiel/resultats_par_niveau_subcom_t1_france_entiere.csv", "2022", "T1"),
    ("/FileStore/tables/MSPR_presidentiel/resultats_par_niveau_subcom_t2_france_entiere__4_.csv", "2022", "T2"),
    ("/FileStore/tables/MSPR_presidentiel/Presidentiel_2017_1erTour.csv", "2017", "T1"),
    ("/FileStore/tables/MSPR_presidentiel/presidentielle_2017_Tour2.csv", "2017", "T2"),
    ("/FileStore/tables/MSPR_presidentiel/presidentiel_2012_T1.csv", "2012", "T1"),
    ("/FileStore/tables/MSPR_presidentiel/presidentiel_2012_t2.csv", "2012", "T2")
]

# Helper: clean column names to snake_case
def clean_columns(df):
    for col_name in df.columns:
        new_name = col_name.lower().strip().replace(" ", "_").replace("%", "pct").replace("/", "_").replace(".", "")
        df = df.withColumnRenamed(col_name, new_name)
    if "exprim√©s" in df.columns:
        df = df.withColumnRenamed("exprim√©s", "exprimes")
    return df

# Step 1: BRONZE - Ingestion brute
bronze_dfs = []
for file_path, year, tour in RAW_FILES:
    df = spark.read.option("header", "true").option("inferSchema", "true").csv(file_path)
    df = df.withColumn("ingestion_date", current_timestamp()) \
           .withColumn("annee", lit(year)) \
           .withColumn("tour", lit(tour))
    df.write.mode("overwrite").parquet(f"{BRONZE_PATH}/election_{year}_{tour}.parquet")
    bronze_dfs.append(df)

# Step 2: SILVER - Nettoyage et enrichissement
silver_dfs = []
for df in bronze_dfs:
    df = clean_columns(df)
    df = df.dropna(how="all").dropDuplicates()

    if "votants" in df.columns and "inscrits" in df.columns:
        df = df.withColumn("taux_participation", (col("votants") / col("inscrits")))
    if "abstentions" in df.columns and "inscrits" in df.columns:
        df = df.withColumn("taux_abstention", (col("abstentions") / col("inscrits")))
    if "blancs" in df.columns and "votants" in df.columns:
        df = df.withColumn("taux_blancs", (col("blancs") / col("votants")))

    if "code_du_d√©partement" in df.columns and "code_de_la_commune" in df.columns:
        df = df.withColumn(
            "code_insee",
            concat(
                lpad(col("code_du_d√©partement").cast(StringType()), 2, "0"),
                lpad(col("code_de_la_commune").cast(StringType()), 3, "0")
            )
        )

    df.write.mode("overwrite").parquet(f"{SILVER_PATH}/election_{df.select('annee').first()[0]}_{df.select('tour').first()[0]}.parquet")
    silver_dfs.append(df)

# Step 3: GOLD - Unification enrichie
from pyspark.sql.functions import lower, trim

gold_columns = ["code_du_d√©partement", "libell√©_du_d√©partement", "inscrits", "abstentions", "votants", "exprimes", "annee", "tour", "taux_participation", "taux_abstention", "taux_blancs", "code_insee"]
gold_df = None
for df in silver_dfs:
    available_cols = [col for col in gold_columns if col in df.columns]
    current = df.select(*available_cols)
    gold_df = current if gold_df is None else gold_df.unionByName(current, allowMissingColumns=True)

# üéØ Filtrage d√©partement ou ville
ville_ou_departement = "33063"  # Bordeaux ou autre c'est la ou on modifie pour le filtrage du d√©partement ou de la ville 
filtre_gold = gold_df.filter(col("code_insee") == ville_ou_departement)
filtre_gold.write.mode("overwrite").parquet(f"{GOLD_PATH}/filtre_elections_{ville_ou_departement}.parquet")

# Export full gold aussi
gold_df.write.mode("overwrite").parquet(f"{GOLD_PATH}/elections_unifiees.parquet")
gold_df.show(10)

# Step 4: EXTRACTION PAR CANDIDAT
candidat_dfs = []
for df in silver_dfs:
    if "nom" in df.columns and "pr√©nom" in df.columns and "voix" in df.columns and "exprimes" in df.columns:
        candidat_df = df.select(
            "code_insee", "annee", "tour", "nom", "pr√©nom", "voix", "exprimes",
            "taux_participation", "taux_abstention", "taux_blancs"
        ).withColumn("nom_complet", expr("concat(`pr√©nom`, ' ', nom)")) \
         .withColumn("pct_voix_exprimes", col("voix") / col("exprimes"))

        candidat_df = candidat_df.select(
            "code_insee", "annee", "tour", "nom_complet", "voix", "pct_voix_exprimes",
            "taux_participation", "taux_abstention", "taux_blancs"
        )

        candidat_dfs.append(candidat_df)

if candidat_dfs:
    candidats_all = candidat_dfs[0]
    for d in candidat_dfs[1:]:
        candidats_all = candidats_all.unionByName(d, allowMissingColumns=True)

    candidats_all.write.mode("overwrite").parquet(f"{CANDIDAT_PATH}/resultats_par_candidat.parquet")
    candidats_all.show(10)
