{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fce529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bronze step association\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "base_dir = \"c:/Users/darka/Desktop/Projets/Elexxion/\"\n",
    "input_dir = os.path.join(base_dir, \"association/raw\")\n",
    "valid_dir = os.path.join(base_dir, \"association/valid\")\n",
    "parquet_dir = os.path.join(base_dir, \"association/parquet/bronze\")\n",
    "expected_fields = 23\n",
    "delimiter = \";\"\n",
    "\n",
    "os.makedirs(valid_dir, exist_ok=True)\n",
    "os.makedirs(parquet_dir, exist_ok=True)\n",
    "\n",
    "csv_files = glob.glob(os.path.join(input_dir, \"*.csv\"))\n",
    "\n",
    "for input_path in csv_files:\n",
    "  filename = os.path.basename(input_path)\n",
    "  output_path = os.path.join(valid_dir, filename.replace(\".csv\", \"_valid.csv\"))\n",
    "\n",
    "  valid_lines = []\n",
    "  error_lines = []\n",
    "\n",
    "  with open(input_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    for line_number, line in enumerate(file, start=1):\n",
    "      fields = line.strip().split(delimiter)\n",
    "\n",
    "      if len(fields) == expected_fields:\n",
    "        valid_lines.append(line.strip())\n",
    "      else:\n",
    "        error_lines.append((line_number, line.strip()))\n",
    "\n",
    "  with open(output_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "    for line in valid_lines:\n",
    "      output_file.write(line + \"\\n\")\n",
    "\n",
    "valid_csv_files  = glob.glob(os.path.join(valid_dir, \"*.csv\"))\n",
    "\n",
    "for csv_path in valid_csv_files :\n",
    "  filename = os.path.basename(csv_path)\n",
    "  print(f\"Processing file: {filename}\")\n",
    "\n",
    "  match = re.search(r'rna_import_(\\d{8})_dpt_([0-9]{2}|[0-9]{3}|2A|2B|97[1-9]{1}[0-9]{1})', filename)\n",
    "  if match:\n",
    "    full_year = match.group(1)\n",
    "    year = full_year[:4]\n",
    "    dpt = match.group(2)\n",
    "\n",
    "    print(f\"Matched year: {year}, department: {dpt}\")\n",
    "    parquet_filename = f\"df_bronze_association_{year}_dpt_{dpt}.parquet\"\n",
    "  else:\n",
    "    print(f\"[‚ö†Ô∏è Ignored file (unknown pattern) : {filename}\")\n",
    "    continue\n",
    "\n",
    "  parquet_path = os.path.join(parquet_dir, parquet_filename)\n",
    "\n",
    "  df = pd.read_csv(csv_path, sep=delimiter, dtype=str)\n",
    "  df.to_parquet(parquet_path, index=False)\n",
    "  print(f\"Converted to parquet: {parquet_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62874204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silver step association\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "bronze_dir = os.path.join(base_dir, \"association/parquet/bronze\")\n",
    "silver_dir = os.path.join(base_dir, \"association/parquet/silver\")\n",
    "\n",
    "os.makedirs(silver_dir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(bronze_dir):\n",
    "  if filename.endswith(\".parquet\"):\n",
    "    file_path = os.path.join(bronze_dir, filename)\n",
    "    df = pd.read_parquet(file_path)\n",
    "\n",
    "    # Standardize column names\n",
    "    df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Remove empty rows\n",
    "    df = df.dropna(how='all')\n",
    "\n",
    "    # Colums renaming\n",
    "    df.rename(columns={'adrs_codepostal': 'cp'}, inplace=True)\n",
    "    df.rename(columns={'date_publi': 'publication'}, inplace=True)\n",
    "    df.rename(columns={'libcom': 'commune'}, inplace=True)\n",
    "    df.rename(columns={'maj_time': 'maj'}, inplace=True)\n",
    "    df.rename(columns={'objet': 'resume'}, inplace=True)\n",
    "    df.rename(columns={'publication': 'creation'}, inplace=True)\n",
    "    df.rename(columns={'titre': 'nom'}, inplace=True)\n",
    "\n",
    "    # Colums deleting\n",
    "    df = df.drop(\n",
    "      columns=[\n",
    "        \"adr1\",\n",
    "        \"adr2\",\n",
    "        \"adr3\",\n",
    "        \"date_creat\",\n",
    "        \"dir_civilite\",\n",
    "        \"gestion\",\n",
    "        \"groupement\",\n",
    "        \"id_ex\",\n",
    "        \"nature\",\n",
    "        \"objet_social1\",\n",
    "        \"objet_social2\",\n",
    "        \"observation\",\n",
    "        \"position\",\n",
    "        \"rup_mi\",\n",
    "        \"siret\",\n",
    "        \"siteweb\"\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    # Save as Parquet with '_df_silver' prefix\n",
    "    silver_filename = filename.replace(\"df_bronze\", \"df_silver\")\n",
    "    silver_file_path = os.path.join(silver_dir, silver_filename)\n",
    "\n",
    "    df.to_parquet(silver_file_path, index=False)\n",
    "    print(f\"‚úÖ Silver files saved : {silver_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a02bf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Fichier agr√©g√© sauvegard√© : df_gold_association_2025_aggregated.parquet\n"
     ]
    }
   ],
   "source": [
    "# Gold step association\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = \"c:/Users/darka/Desktop/Projets/Elexxion/\"\n",
    "silver_dir = os.path.join(base_dir, \"association/parquet/silver\")\n",
    "gold_dir = os.path.join(base_dir, \"association/parquet/gold\")\n",
    "os.makedirs(gold_dir, exist_ok=True)\n",
    "\n",
    "df_list = []\n",
    "\n",
    "# Load silvers Parquet files\n",
    "for filename in os.listdir(silver_dir):\n",
    "  if filename.endswith(\".parquet\"):\n",
    "    file_path = os.path.join(silver_dir, filename)\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df_list.append(df)\n",
    "\n",
    "if df_list:\n",
    "  df_gold = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "  df_gold[\"cp\"] = df_gold[\"cp\"].astype(str).str.strip()\n",
    "  df_gold = df_gold[df_gold[\"cp\"].str.match(r\"^\\d{5}$\")]\n",
    "\n",
    "  df_gold[\"departement\"] = df_gold[\"cp\"].str[:2]\n",
    "  df_gold[\"annee\"] = pd.to_datetime(df_gold[\"maj\"], errors=\"coerce\").dt.year\n",
    "\n",
    "  df_agg = df_gold.groupby([\"departement\", \"annee\"]).size().reset_index(name=\"nombre\")\n",
    "  df_agg = df_agg.sort_values(by=[\"departement\", \"annee\"])\n",
    "\n",
    "  df_agg[\"cumul_global\"] = df_agg.groupby(\"departement\")[\"nombre\"].cumsum()\n",
    "\n",
    "  agg_filename = \"df_gold_association_2025_aggregated.parquet\"\n",
    "  agg_file_path = os.path.join(gold_dir, agg_filename)\n",
    "  df_agg.to_parquet(agg_file_path, index=False)\n",
    "  print(f\"üìä Aggregated file saved : {agg_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
